{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can Topological Divergences Help Predict the Largest Lyapunov Exponent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook generates dynamic system trajectory data then analyses multiple features for supervised learning of the largest Lyapunov exponent (classification and regression). Classical numeric methods, TDA-based methods, Horizontal Visibility methods, and our newly introduced topological divergences are compared.\n",
    "\n",
    "- classic neighbour-tracing estimators from Rosenstein, Eckmann, and Kantz\n",
    "- ordinal partition network embedded persistence measures from Myers\n",
    "- $k$-nearest neighbour graph embedded persistence measures from Myers\n",
    "- Betti vector norms on embedded trajectories from GÃ¼zel\n",
    "- topological divergences (the main contribution)\n",
    "\n",
    "Topological divergences are scalar or vector valued measures of the difference between the sublevel and superlevel filtrations over a scalar function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect imports for cells below\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from functools import partial\n",
    "from TimeSeriesMergeTreeSimple import TimeSeriesMergeTree as TSMT\n",
    "from ipyparallel import require\n",
    "import ipyparallel as ipp\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tree_offset_divergence import get_offset_divergences\n",
    "from tree_offset_divergence import div_names as merge_tree_divergence_names\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "from trajectories import generate_trajectories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide clients to an ipyparallel cluster for faster parallel processing\n",
    "\n",
    "clients = ipp.Client()\n",
    "dv = clients.direct_view()\n",
    "lbv = clients.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to remove scale bias in supervised learning\n",
    "\n",
    "def scale(ts):\n",
    "    \"\"\"Make range of ts fall between 0 and 1\"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    return scaler.fit_transform(ts.reshape(-1, 1)).flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaotic system data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the trajectory generation criteria\n",
    "\n",
    "SEED = 54321  # consistent random number generation\n",
    "SAMPLES = 5000  # number of trajectories\n",
    "LENGTH = 2000  # number of points per trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the actual system data to analyse\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "filename_train_data = os.path.join(\"outputs/white_noise\", \"__\".join(map(str, [SEED, LENGTH, SAMPLES])) + \"__train_data.pkl\")\n",
    "if not os.path.exists(filename_train_data):\n",
    "    with open(filename_train_data, \"wb\") as file:\n",
    "        data_ = generate_trajectories(RANDOM_SEED=SEED, TS_LENGTH=LENGTH, CONTROL_PARAM_SAMPLES=SAMPLES)\n",
    "        pickle.dump(data_, file)\n",
    "\n",
    "with open(filename_train_data, \"rb\") as file:\n",
    "    system_training_data = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove relative scale (amplitude) as a feature that could be used in supevised learning\n",
    "\n",
    "for system in system_training_data:\n",
    "    trajectories = system_training_data[system][\"trajectories\"]\n",
    "    trajectories = list(map(scale, trajectories))\n",
    "    system_training_data[system][\"trajectories\"] = trajectories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define machine learning models to train on the Lyapunov estimates\n",
    "\n",
    "def score_features_train(feature_names, features, y_true, cv=5, n_repeats=5, ML_SEED=123):\n",
    "    \"\"\"Score various supervised ML models on supplied features give a ground truth.\n",
    "    \n",
    "    For classification, assumes ground truth y_true>0 is the positive class.\n",
    "    \"\"\"\n",
    "\n",
    "    # assume vectorial features; if scalar, add an extra dimension\n",
    "    features = np.array(features)\n",
    "    if features.ndim == 2:\n",
    "        features = features[..., np.newaxis]\n",
    "    n_samples, n_features, feature_vector_length = features.shape\n",
    "\n",
    "    CLASSIFIER_CV = RepeatedStratifiedKFold(n_splits=cv, random_state=ML_SEED, n_repeats=n_repeats)\n",
    "    REGRESSOR_CV = RepeatedKFold(n_splits=cv, random_state=ML_SEED*2, n_repeats=n_repeats)\n",
    "\n",
    "    y = y_true\n",
    "    pos_mask = y>0\n",
    "    y_classes = y>0\n",
    "\n",
    "    classification_scorer = \"f1\"\n",
    "    regression_scorer = \"neg_mean_squared_error\"\n",
    "\n",
    "\n",
    "    for i in range(n_features):\n",
    "        feature_name = feature_names[i]\n",
    "        X = features[:, i, :].reshape(n_samples, -1)\n",
    "\n",
    "        SVC_pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(random_state=ML_SEED))])\n",
    "        SVC_clf = GridSearchCV(SVC_pipe, {'svc__C':[0.01, 0.1, 1, 10, 100]}, scoring=classification_scorer, n_jobs=-2, refit=True, cv=CLASSIFIER_CV)\n",
    "        SVC_clf.fit(X, y_classes)\n",
    "        SVC_scores = cross_val_score(SVC_clf.best_estimator_, X, y_classes, scoring=classification_scorer, cv=CLASSIFIER_CV, n_jobs=-2)\n",
    "\n",
    "        KNC_pipe = Pipeline([('scaler', StandardScaler()), ('knc', KNeighborsClassifier())])\n",
    "        KNC_clf = GridSearchCV(KNC_pipe, {'knc__n_neighbors':[5, 10, 15, 20, 25, 30]}, scoring=classification_scorer, n_jobs=-2, refit=True, cv=CLASSIFIER_CV)\n",
    "        KNC_clf.fit(X, y_classes)\n",
    "        KNC_scores = cross_val_score(KNC_clf.best_estimator_, X, y_classes, scoring=classification_scorer, cv=CLASSIFIER_CV, n_jobs=-2)\n",
    "\n",
    "        MLPC_pipe = Pipeline([('scaler', StandardScaler()), ('mlp', MLPClassifier(learning_rate='adaptive', random_state=ML_SEED, max_iter=400))])\n",
    "        MLPC_clf = GridSearchCV(MLPC_pipe, {'mlp__alpha':[0.00001, 0.0001, 0.001, 0.01], 'mlp__hidden_layer_sizes':[(10,), (20,), (10,5,), (20,5)]}, scoring=classification_scorer, n_jobs=-2, refit=True, cv=CLASSIFIER_CV)\n",
    "        MLPC_clf.fit(X, y_classes)\n",
    "        MLPC_scores = cross_val_score(MLPC_clf.best_estimator_, X, y_classes, scoring=classification_scorer, cv=CLASSIFIER_CV, n_jobs=-2)\n",
    "\n",
    "        KNR_all_pipe = Pipeline([('scaler', StandardScaler()), ('knr', KNeighborsRegressor(weights='distance'))])\n",
    "        KNR_all_clf = GridSearchCV(KNR_all_pipe, {'knr__n_neighbors': [5, 10, 15, 20, 25, 30]}, n_jobs=-2, scoring=regression_scorer, cv=REGRESSOR_CV, refit=True)\n",
    "        KNR_all_clf.fit(X, y)\n",
    "        KNR_all_scores = cross_val_score(KNR_all_clf.best_estimator_, X, y, scoring=regression_scorer, cv=REGRESSOR_CV, n_jobs=-2)\n",
    "\n",
    "        # KNR_chaos_pipe = Pipeline([('scaler', StandardScaler()), ('knr', KNeighborsRegressor(weights='distance'))])\n",
    "        # KNR_chaos_clf = GridSearchCV(KNR_chaos_pipe, {'knr__n_neighbors': [5, 10, 15, 20, 25, 30]}, n_jobs=-2, scoring=regression_scorer, cv=REGRESSOR_CV, refit=True)\n",
    "        # KNR_chaos_clf.fit(X[pos_mask], y[pos_mask])\n",
    "        # KNR_chaos_scores = cross_val_score(KNR_chaos_clf.best_estimator_, X[pos_mask], y[pos_mask], scoring=regression_scorer, cv=REGRESSOR_CV, n_jobs=-2)\n",
    "\n",
    "        SVR_all_pipe = Pipeline([('scaler', StandardScaler()), ('svr', SVR())])\n",
    "        SVR_all_clf = GridSearchCV(SVR_all_pipe, {'svr__C':[0.01, 0.1, 1, 10, 100]}, scoring=regression_scorer, n_jobs=-2, refit=True, cv=REGRESSOR_CV)\n",
    "        SVR_all_clf.fit(X, y)\n",
    "        SVR_all_scores = cross_val_score(SVR_all_clf.best_estimator_, X, y, scoring=regression_scorer, cv=REGRESSOR_CV, n_jobs=-2)\n",
    "\n",
    "        # SVR_chaos_pipe = Pipeline([('scaler', StandardScaler()), ('svr', SVR())])\n",
    "        # SVR_chaos_clf = GridSearchCV(SVR_chaos_pipe, {'svr__C':[0.01, 0.1, 1, 10, 100]}, scoring=regression_scorer, n_jobs=-2, refit=True, cv=REGRESSOR_CV)\n",
    "        # SVR_chaos_clf.fit(X[pos_mask], y[pos_mask])\n",
    "        # SVR_chaos_scores = cross_val_score(SVR_chaos_clf.best_estimator_, X[pos_mask], y[pos_mask], scoring=regression_scorer, cv=REGRESSOR_CV, n_jobs=-2)\n",
    "\n",
    "        MLPR_all_pipe = Pipeline([('scaler', StandardScaler()), ('mlp', MLPRegressor(learning_rate='adaptive', random_state=ML_SEED, max_iter=400))])\n",
    "        MLPR_all_clf = GridSearchCV(MLPR_all_pipe, {'mlp__alpha':[0.00001, 0.0001, 0.001, 0.01], 'mlp__hidden_layer_sizes':[(10,), (20,), (10,5,), (20,5)]}, scoring=regression_scorer, n_jobs=-2, refit=True, cv=REGRESSOR_CV)\n",
    "        MLPR_all_clf.fit(X, y)\n",
    "        MLPR_all_scores = cross_val_score(MLPR_all_clf.best_estimator_, X, y, scoring=regression_scorer, cv=REGRESSOR_CV, n_jobs=-2)\n",
    "\n",
    "        # MLPR_chaos_pipe = Pipeline([('scaler', StandardScaler()), ('mlp', MLPRegressor(learning_rate='adaptive', random_state=ML_SEED, max_iter=400))])\n",
    "        # MLPR_chaos_clf = GridSearchCV(MLPR_chaos_pipe, {'mlp__alpha':[0.00001, 0.0001, 0.001, 0.01], 'mlp__hidden_layer_sizes':[(10,), (20,), (10,5,), (20,5)]}, scoring=regression_scorer, n_jobs=-2, refit=True, cv=REGRESSOR_CV)\n",
    "        # MLPR_chaos_clf.fit(X[pos_mask], y[pos_mask])\n",
    "        # MLPR_chaos_scores = cross_val_score(MLPR_chaos_clf.best_estimator_, X[pos_mask], y[pos_mask], scoring=regression_scorer, cv=REGRESSOR_CV, n_jobs=-2)\n",
    "\n",
    "        # add attribute to check if a model is for all data or just chaotic data\n",
    "        # setattr(KNR_chaos_clf, \"chaos\", True)\n",
    "        # setattr(SVR_chaos_clf, \"chaos\", True)\n",
    "        # setattr(MLPR_chaos_clf, \"chaos\", True)\n",
    "\n",
    "        yield {\n",
    "            feature_name: {\n",
    "                \"scores\": {\n",
    "                    \"SVC\": SVC_scores,\n",
    "                    \"SVR\": SVR_all_scores,\n",
    "                    \"MLPC\": MLPC_scores,\n",
    "                    \"MLPR\": MLPR_all_scores,\n",
    "                    \"KNC\": KNC_scores,\n",
    "                    \"KNR\": KNR_all_scores,\n",
    "                    # \"KNR_chaos\": KNR_chaos_scores,\n",
    "                    # \"SVR_chaos\": SVR_chaos_scores,\n",
    "                    # \"MLPR_chaos\": MLPR_chaos_scores,\n",
    "                },\n",
    "                \"models\": {\n",
    "                    \"SVC\": SVC_clf,\n",
    "                    \"SVR\": SVR_all_clf,\n",
    "                    \"MLPC\": MLPC_clf,\n",
    "                    \"MLPR\": MLPR_all_clf,\n",
    "                    \"KNC\": KNC_clf,\n",
    "                    \"KNR\": KNR_all_clf,\n",
    "                    # \"KNR_chaos\": KNR_chaos_clf,\n",
    "                    # \"SVR_chaos\": SVR_chaos_clf,\n",
    "                    # \"MLPR_chaos\": MLPR_chaos_clf,\n",
    "                }\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply trained machine models to features from new unseen data\n",
    "\n",
    "def score_features_test(feature_names, features, y_true, trained_models):\n",
    "    \"\"\"Predict using features as input to trained models and score against ground truth.\n",
    "    \n",
    "    For classification, assumes ground truth y_true>0 is the positive class.\n",
    "    \"\"\"\n",
    "\n",
    "    # assume vectorial features; if scalar, add an extra dimension\n",
    "    features = np.array(features)\n",
    "    if features.ndim == 2:\n",
    "        features = features[..., np.newaxis]\n",
    "    n_samples, n_features, feature_vector_length = features.shape\n",
    "    \n",
    "    is_classifier = lambda clf: hasattr(clf, \"classes_\")\n",
    "\n",
    "    pos_mask = y_true>0\n",
    "\n",
    "    for i in range(n_features):\n",
    "        feature_name = feature_names[i]\n",
    "        X = features[:, i, :].reshape(n_samples, -1)\n",
    "\n",
    "        yield {\n",
    "            feature_name: {\n",
    "                # \"predictions\": {\n",
    "                #     model_name: trained_model.predict(\n",
    "                #         X[pos_mask] if getattr(trained_model, \"chaos\", False) else X\n",
    "                #     ) for model_name, trained_model in trained_models[feature_name].items()\n",
    "                # },\n",
    "                # \"r2_scores\": {\n",
    "                #     model_name: trained_model.score(\n",
    "                #         (X[pos_mask] if getattr(trained_model, \"chaos\", False) else X),\n",
    "                #         (y_true[pos_mask] if getattr(trained_model, \"chaos\", False) else (pos_mask if is_classifier(trained_model) else y_true))\n",
    "                #     )\n",
    "                #     for model_name, trained_model in trained_models[feature_name].items()\n",
    "                # },\n",
    "                \"predictions\": {\n",
    "                    model_name: trained_model.predict(X) for model_name, trained_model in trained_models[feature_name].items()\n",
    "                },\n",
    "                \"r2_scores\": {\n",
    "                    model_name: trained_model.score(X, (pos_mask if is_classifier(trained_model) else y_true))\n",
    "                    for model_name, trained_model in trained_models[feature_name].items()\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SEED = SEED * 2\n",
    "TEST_LENGTH = LENGTH\n",
    "TEST_SAMPLES = 1001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the test system data to analyse\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "filename_test_data = os.path.join(\"outputs/white_noise\", \"__\".join(map(str, [SEED, LENGTH, SAMPLES, TEST_SEED, TEST_LENGTH, TEST_SAMPLES])) + \"__test_data.pkl\")\n",
    "if not os.path.exists(filename_test_data):\n",
    "    with open(filename_test_data, \"wb\") as file:\n",
    "        data_ = generate_trajectories(RANDOM_SEED=TEST_SEED, TS_LENGTH=TEST_LENGTH, CONTROL_PARAM_SAMPLES=TEST_SAMPLES)\n",
    "        pickle.dump(data_, file)\n",
    "\n",
    "with open(filename_test_data, \"rb\") as file:\n",
    "    system_test_data = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove relative scale (amplitude) as a feature that could be used in supevised learning\n",
    "\n",
    "for system in system_test_data:\n",
    "    trajectories = system_test_data[system][\"trajectories\"]\n",
    "    trajectories = list(map(scale, trajectories))\n",
    "    system_test_data[system][\"trajectories\"] = trajectories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define utility functions\n",
    "\n",
    "def make_inf_column_finite(arr):\n",
    "    \"\"\"Convert -inf and +inf to min finite value in each column.\"\"\"\n",
    "\n",
    "    arr_isinf = np.isinf(arr)\n",
    "    col_mins = np.min(ma.masked_array(arr, mask=arr_isinf, fill_value=0), axis=0)\n",
    "\n",
    "    for row_idx in range(arr.shape[0]):\n",
    "        for col_idx in range(arr.shape[1]):\n",
    "            if np.isinf(arr[row_idx, col_idx]):\n",
    "                arr[row_idx, col_idx] = col_mins[col_idx]\n",
    "                arr[np.isnan(arr)] = -1e-12\n",
    "\n",
    "    return arr\n",
    "\n",
    "def get_scores_from_predictions(y_pred, y_true=None):\n",
    "    \"\"\"Compute f1 and negative mean squared error scores for predictions.\"\"\"\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import f1_score\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    chaos = y_true > 0\n",
    "    mse_all = mean_squared_error(y_true, y_pred)\n",
    "    f1_all = f1_score(chaos, y_pred>0)\n",
    "    spearmanr_all = stats.spearmanr(y_pred, y_true)[0]\n",
    "    pearsonr_all = stats.pearsonr(y_pred, y_true)[0]\n",
    "\n",
    "    results = {\n",
    "        \"Raw F1\": f1_all,\n",
    "        \"Raw MSE\": -mse_all,\n",
    "        \"Raw Spearman\": spearmanr_all,\n",
    "        \"Raw Pearson\": pearsonr_all,\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\lambda_{\\max}$ Estimator Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generic pipeline to compute a set of features and apply them to predicting $\\lambda_{\\max}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up caching\n",
    "from joblib import Memory\n",
    "location = './cachedir'\n",
    "memory = Memory(location, verbose=0)\n",
    "\n",
    "# import the feature function and the list of names of features\n",
    "from hvg_estimates import get_hvg_estimates, hvg_names\n",
    "from tree_offset_divergence import get_offset_divergences_vec, div_names\n",
    "from crocker_estimates import get_crocker_estimates, crocker_names\n",
    "\n",
    "# set the system for analysis\n",
    "SYSTEM = \"logistic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scoring(feature_func, feature_names, trajectories_train, trajectories_test, y_train, y_test, lbv, cache_key_info=None):\n",
    "\n",
    "    # compute features for training and test data sets\n",
    "    batch_size = 1000\n",
    "\n",
    "    train_data_features = []\n",
    "    for batch_start_idx in range(0, len(trajectories_train), batch_size):\n",
    "        batch_end_idx = min(batch_start_idx + batch_size, len(trajectories_train))\n",
    "        train_data_features += list(lbv.map_sync(feature_func, trajectories_train[batch_start_idx:batch_end_idx]))\n",
    "    train_data_features = np.array(train_data_features)\n",
    "\n",
    "    test_data_features = []\n",
    "    for batch_start_idx in range(0, len(trajectories_test), batch_size):\n",
    "        batch_end_idx = min(batch_start_idx + batch_size, len(trajectories_test))\n",
    "        test_data_features += list(lbv.map_sync(feature_func, trajectories_test[batch_start_idx:batch_end_idx]))\n",
    "    test_data_features = np.array(test_data_features)\n",
    "    \n",
    "    # train the models and gather the results\n",
    "    training_results = {}\n",
    "    for result in score_features_train(feature_names, train_data_features, y_train):\n",
    "        training_results |= result\n",
    "\n",
    "    # extract scores and trained models\n",
    "    training_scores = {k:v[\"scores\"] for k,v in training_results.items()}\n",
    "    trained_models = {k:v[\"models\"] for k,v in training_results.items()}\n",
    "\n",
    "    # average the scores for each feature and model over all cross validation runs\n",
    "    training_scores_df = pd.DataFrame(training_scores)\n",
    "    training_scores_df = training_scores_df.applymap(np.mean).T\n",
    "\n",
    "    # apply the trained models to new data and gather the results\n",
    "    test_results = {}\n",
    "    for result in score_features_test(feature_names, test_data_features, y_test, trained_models):\n",
    "            test_results |= result\n",
    "\n",
    "    # extract scores, predictions, and correlations on the test data\n",
    "    test_scores = {k:v[\"r2_scores\"] for k,v in test_results.items()}\n",
    "    test_predictions = {k:v[\"predictions\"] for k,v in test_results.items()}\n",
    "    test_correlations = {\n",
    "        k: {\n",
    "            \"SVR Spearman\": stats.spearmanr(v[\"SVR\"], y_test)[0],\n",
    "            \"SVR Pearson\": stats.pearsonr(v[\"SVR\"], y_test)[0],\n",
    "            \"MLPR Spearman\": stats.spearmanr(v[\"MLPR\"], y_test)[0],\n",
    "            \"MLPR Pearson\": stats.pearsonr(v[\"MLPR\"], y_test)[0],\n",
    "            \"KNR Spearman\": stats.spearmanr(v[\"KNR\"], y_test)[0],\n",
    "            \"KNR Pearson\": stats.pearsonr(v[\"KNR\"], y_test)[0],\n",
    "        }\n",
    "        for k,v in test_predictions.items()\n",
    "    }\n",
    "\n",
    "    # get scores for each feature and model as a dataframe\n",
    "    test_scores_df = pd.DataFrame(test_scores).T\n",
    "    test_correlations_df = pd.DataFrame(test_correlations).T\n",
    "\n",
    "    # also get correlations and scoring metrics for the raw feature values (when they are scalars)\n",
    "    if test_data_features.ndim == 2:\n",
    "        # features are single scalar values\n",
    "        raw_scores = map(partial(get_scores_from_predictions, y_true=y_test), test_data_features.T)\n",
    "        raw_scores_df = pd.DataFrame(raw_scores)\n",
    "        raw_scores_df.index = feature_names\n",
    "\n",
    "\n",
    "    if test_data_features.ndim == 2:\n",
    "        r2_features = test_data_features[...,np.newaxis]\n",
    "    else:\n",
    "        r2_features = test_data_features.copy()\n",
    "\n",
    "    # fit an ordinary least squares model and correlate the predictions with y_true\n",
    "    r2_scores = []\n",
    "    n_samples, n_features, feature_vector_length = r2_features.shape\n",
    "    for i in range(n_features):\n",
    "        feature_name = feature_names[i]\n",
    "        X = r2_features[:, i, :].reshape(n_samples, -1)\n",
    "        clf = LinearRegression()\n",
    "        clf.fit(X, y_test)\n",
    "        y_pred = clf.predict(X)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        r2_adjusted = 1 - (1-r2)*(n_samples-1)/(n_samples-feature_vector_length-1)\n",
    "        score = {\n",
    "            \"Raw R2\": r2,\n",
    "            \"Raw R2 Adjusted\": r2_adjusted,\n",
    "        }\n",
    "        r2_scores.append(score)\n",
    "    r2_scores_df = pd.DataFrame(r2_scores)\n",
    "    r2_scores_df.index = feature_names\n",
    "\n",
    "    return training_scores_df, test_scores_df, test_correlations_df, raw_scores_df, r2_scores_df, test_data_features, test_predictions\n",
    "\n",
    "feature_scoring = memory.cache(feature_scoring, ignore=[\"feature_func\", \"lbv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = feature_scoring(\n",
    "    get_crocker_estimates,\n",
    "    crocker_names,\n",
    "    system_training_data[SYSTEM][\"trajectories\"],\n",
    "    system_test_data[SYSTEM][\"trajectories\"],\n",
    "    system_training_data[SYSTEM][\"lces\"],\n",
    "    system_test_data[SYSTEM][\"lces\"],\n",
    "    lbv,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear(warn=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3682469/3615873576.py:1: UserWarning: Persisting input arguments took 0.85s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  results = feature_scoring(\n"
     ]
    }
   ],
   "source": [
    "results = feature_scoring(\n",
    "    get_hvg_estimates,\n",
    "    hvg_names,\n",
    "    system_training_data[SYSTEM][\"trajectories\"],\n",
    "    system_test_data[SYSTEM][\"trajectories\"],\n",
    "    system_training_data[SYSTEM][\"lces\"],\n",
    "    system_test_data[SYSTEM][\"lces\"],\n",
    "    lbv,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete=True\n",
    "offsets=range(1, 252, 50)\n",
    "get_offset_divergences_vec_func = partial(get_offset_divergences_vec, offsets=offsets, discrete=discrete)\n",
    "\n",
    "\n",
    "results = feature_scoring(\n",
    "    get_offset_divergences_vec_func,\n",
    "    div_names,\n",
    "    system_training_data[SYSTEM][\"trajectories\"],\n",
    "    system_test_data[SYSTEM][\"trajectories\"],\n",
    "    system_training_data[SYSTEM][\"lces\"],\n",
    "    system_test_data[SYSTEM][\"lces\"],\n",
    "    lbv,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVC</th>\n",
       "      <th>SVR</th>\n",
       "      <th>MLPC</th>\n",
       "      <th>MLPR</th>\n",
       "      <th>KNC</th>\n",
       "      <th>KNR</th>\n",
       "      <th>SVC</th>\n",
       "      <th>SVR</th>\n",
       "      <th>MLPC</th>\n",
       "      <th>MLPR</th>\n",
       "      <th>...</th>\n",
       "      <th>MLPR Spearman</th>\n",
       "      <th>MLPR Pearson</th>\n",
       "      <th>KNR Spearman</th>\n",
       "      <th>KNR Pearson</th>\n",
       "      <th>Raw F1</th>\n",
       "      <th>Raw MSE</th>\n",
       "      <th>Raw Spearman</th>\n",
       "      <th>Raw Pearson</th>\n",
       "      <th>R2</th>\n",
       "      <th>R2 adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HVG L1</th>\n",
       "      <td>0.884222</td>\n",
       "      <td>-0.032705</td>\n",
       "      <td>0.885750</td>\n",
       "      <td>-0.033519</td>\n",
       "      <td>0.902571</td>\n",
       "      <td>-0.134156</td>\n",
       "      <td>0.888760</td>\n",
       "      <td>-0.030102</td>\n",
       "      <td>0.887731</td>\n",
       "      <td>-0.030410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836283</td>\n",
       "      <td>0.791566</td>\n",
       "      <td>0.842148</td>\n",
       "      <td>0.735309</td>\n",
       "      <td>0.882057</td>\n",
       "      <td>-0.085039</td>\n",
       "      <td>0.748351</td>\n",
       "      <td>0.478052</td>\n",
       "      <td>0.228534</td>\n",
       "      <td>0.227762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HVG L2</th>\n",
       "      <td>0.882129</td>\n",
       "      <td>-0.034018</td>\n",
       "      <td>0.880270</td>\n",
       "      <td>-0.033858</td>\n",
       "      <td>0.923050</td>\n",
       "      <td>-0.104001</td>\n",
       "      <td>0.888265</td>\n",
       "      <td>-0.031471</td>\n",
       "      <td>0.885264</td>\n",
       "      <td>-0.030545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804743</td>\n",
       "      <td>0.790470</td>\n",
       "      <td>0.840507</td>\n",
       "      <td>0.758225</td>\n",
       "      <td>0.882057</td>\n",
       "      <td>-0.112534</td>\n",
       "      <td>0.679364</td>\n",
       "      <td>0.453315</td>\n",
       "      <td>0.205495</td>\n",
       "      <td>0.204699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HVG Linf</th>\n",
       "      <td>0.878681</td>\n",
       "      <td>-0.035273</td>\n",
       "      <td>0.879638</td>\n",
       "      <td>-0.035784</td>\n",
       "      <td>0.906851</td>\n",
       "      <td>-0.121611</td>\n",
       "      <td>0.886644</td>\n",
       "      <td>-0.031249</td>\n",
       "      <td>0.882486</td>\n",
       "      <td>-0.031779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773138</td>\n",
       "      <td>0.781743</td>\n",
       "      <td>0.832737</td>\n",
       "      <td>0.724134</td>\n",
       "      <td>0.882057</td>\n",
       "      <td>-0.119979</td>\n",
       "      <td>0.672145</td>\n",
       "      <td>0.537012</td>\n",
       "      <td>0.288382</td>\n",
       "      <td>0.287670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HVG W</th>\n",
       "      <td>0.876152</td>\n",
       "      <td>-0.039311</td>\n",
       "      <td>0.879551</td>\n",
       "      <td>-0.040131</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>-0.168278</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>-0.033762</td>\n",
       "      <td>0.890286</td>\n",
       "      <td>-0.035147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848629</td>\n",
       "      <td>0.754798</td>\n",
       "      <td>0.861041</td>\n",
       "      <td>0.722142</td>\n",
       "      <td>0.882057</td>\n",
       "      <td>-0.067001</td>\n",
       "      <td>0.843535</td>\n",
       "      <td>0.687901</td>\n",
       "      <td>0.473208</td>\n",
       "      <td>0.472680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SVC       SVR      MLPC      MLPR       KNC       KNR  \\\n",
       "HVG L1    0.884222 -0.032705  0.885750 -0.033519  0.902571 -0.134156   \n",
       "HVG L2    0.882129 -0.034018  0.880270 -0.033858  0.923050 -0.104001   \n",
       "HVG Linf  0.878681 -0.035273  0.879638 -0.035784  0.906851 -0.121611   \n",
       "HVG W     0.876152 -0.039311  0.879551 -0.040131  0.875556 -0.168278   \n",
       "\n",
       "               SVC       SVR      MLPC      MLPR  ...  MLPR Spearman  \\\n",
       "HVG L1    0.888760 -0.030102  0.887731 -0.030410  ...       0.836283   \n",
       "HVG L2    0.888265 -0.031471  0.885264 -0.030545  ...       0.804743   \n",
       "HVG Linf  0.886644 -0.031249  0.882486 -0.031779  ...       0.773138   \n",
       "HVG W     0.882812 -0.033762  0.890286 -0.035147  ...       0.848629   \n",
       "\n",
       "          MLPR Pearson  KNR Spearman  KNR Pearson    Raw F1   Raw MSE  \\\n",
       "HVG L1        0.791566      0.842148     0.735309  0.882057 -0.085039   \n",
       "HVG L2        0.790470      0.840507     0.758225  0.882057 -0.112534   \n",
       "HVG Linf      0.781743      0.832737     0.724134  0.882057 -0.119979   \n",
       "HVG W         0.754798      0.861041     0.722142  0.882057 -0.067001   \n",
       "\n",
       "          Raw Spearman  Raw Pearson        R2  R2 adjusted  \n",
       "HVG L1        0.748351     0.478052  0.228534     0.227762  \n",
       "HVG L2        0.679364     0.453315  0.205495     0.204699  \n",
       "HVG Linf      0.672145     0.537012  0.288382     0.287670  \n",
       "HVG W         0.843535     0.687901  0.473208     0.472680  \n",
       "\n",
       "[4 rows x 24 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([*results[:5]], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chaos-chapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
